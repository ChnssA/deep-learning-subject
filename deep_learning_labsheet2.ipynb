{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtcN+B5bDfzixhWgQQMaSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChnssA/deep-learning-subject/blob/main/deep_learning_labsheet2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2: Refresh Computer Vision\n",
        "1. Load the same image using OpenCV and PIL.\n",
        "• Print the shape, dtype, and value range for each.\n",
        "• Explain any differences you observe.\n",
        "2. Convert both images to grayscale.\n",
        "• Verify whether the outputs are numerically identical.\n",
        "• If not, explain why.\n",
        "3. Read a color image using OpenCV and display it using matplotlib.\n",
        "• Why do the colors look incorrect?\n",
        "• Fix the issue and explain the root cause.\n",
        "4. Split an RGB image into individual channels.\n",
        "• Visualize each channel.\n",
        "• Which objects appear brightest in each channel and why?\n",
        "5. Convert an image from RGB to HSV.\n",
        "• Identify pixels corresponding to a specific color (e.g., red).\n",
        "• Explain why HSV is preferable to RGB for this task.\n",
        "6. Resize an image to 224×224.\n",
        "• Identify geometric distortions.\n",
        "• Propose a method to preserve aspect ratio.\n",
        "7. Normalize an image to the range [0,1].\n",
        "• What happens if normalization is applied twice?\n",
        "• How does this affect visualization"
      ],
      "metadata": {
        "id": "z56bZ4p_HHNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "a. Create two random 3x3 tensors and perform matrix multiplication. Compute the matrix\n",
        "product and use Py Torch's autograd to calculate the gradient of the result with respect\n",
        "to one of the input tensors\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_FWM8lGIfub0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNWuy5ttfpMY",
        "outputId": "f2434999-c800-4f86-8d6b-9354b9e4afa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            " tensor([[-1.0381, -0.7621, -1.5094],\n",
            "        [ 0.7404,  1.0457, -0.0514],\n",
            "        [ 0.6395, -0.8402,  0.6587]], requires_grad=True)\n",
            "Tensor B:\n",
            " tensor([[-0.8843,  1.7355,  0.2425],\n",
            "        [ 0.3276, -1.2903,  0.9603],\n",
            "        [-0.0389,  0.4359, -1.0522]])\n",
            "Matrix product C:\n",
            " tensor([[ 0.7270, -1.4762,  0.6046],\n",
            "        [-0.3101, -0.0867,  1.2378],\n",
            "        [-0.8664,  2.4810, -1.3448]], grad_fn=<MmBackward0>)\n",
            "Gradient of loss w.r.t A:\n",
            " tensor([[ 1.0936, -0.0024, -0.6551],\n",
            "        [ 1.0936, -0.0024, -0.6551],\n",
            "        [ 1.0936, -0.0024, -0.6551]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Step 1: Create two random 3x3 tensors\n",
        "A = torch.randn(3, 3, requires_grad=True)   # requires_grad=True so we can compute gradients\n",
        "B = torch.randn(3, 3)\n",
        "\n",
        "print(\"Tensor A:\\n\", A)\n",
        "print(\"Tensor B:\\n\", B)\n",
        "\n",
        "# Step 2: Perform matrix multiplication\n",
        "C = torch.matmul(A, B)\n",
        "print(\"Matrix product C:\\n\", C)\n",
        "\n",
        "# Step 3: Define a scalar output (needed for autograd)\n",
        "# For example, take the sum of all elements in C\n",
        "loss = C.sum()\n",
        "\n",
        "# Step 4: Backpropagate to compute gradients\n",
        "loss.backward()\n",
        "\n",
        "# Step 5: Gradient of loss w.r.t. A\n",
        "print(\"Gradient of loss w.r.t A:\\n\", A.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Matrix Multiplication & Autograd\n",
        "Matrix multiplication is handled by torch.matmul() or the @ operator. To use Autograd, we must set requires_grad=True."
      ],
      "metadata": {
        "id": "MHSzU1znMRTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create tensors\n",
        "A = torch.randn(3, 3, requires_grad=True)\n",
        "B = torch.randn(3, 3)\n",
        "\n",
        "# Matrix multiplication\n",
        "C = torch.matmul(A, B)\n",
        "\n",
        "# We need a scalar value to call backward()\n",
        "external_grad = torch.ones_like(C)\n",
        "C.backward(external_grad)\n",
        "\n",
        "print(f\"Gradient of C with respect to A:\\n{A.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FuOeLA3MS78",
        "outputId": "3aca5f37-32b7-4132-e07b-64585e306d3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of C with respect to A:\n",
            "tensor([[-0.1128,  1.0434, -1.0700],\n",
            "        [-0.1128,  1.0434, -1.0700],\n",
            "        [-0.1128,  1.0434, -1.0700]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Broadcasting LogicBroadcasting allows you to perform operations on tensors of different shapes without manually duplicating data.3x1 Tensor + 1x3 Tensor: PyTorch \"stretches\" the 3x1 vertically and the 1x3 horizontally to create two 3x3 matrices before adding them.Math: If $A$ is (3,1) and $B$ is (1,3), $C = A + B$ results in a (3,3) tensor where $C_{ij} = A_i + B_j$."
      ],
      "metadata": {
        "id": "5wfGbplpNBWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([[1], [2], [3]]) # 3x1\n",
        "t2 = torch.tensor([[10, 20, 30]])  # 1x3\n",
        "t3 = torch.randn(3, 3)             # 3x3\n",
        "\n",
        "result = (t1 + t2) * t3\n",
        "print(f\"Resulting Shape: {result.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAfnDL67NFjO",
        "outputId": "d206119a-3757-4913-d9ad-ed73ece567ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resulting Shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Reshaping and SlicingReshaping changes the view of the data without moving it in memory, provided the total number of elements remains the same ($6 \\times 4 = 24$ and $3 \\times 8 = 24$).Reshape: tensor.view(3, 8) or tensor.reshape(3, 8).Slicing: tensor[:, :2] selects all rows (represented by :) and the first two columns (indices 0 and 1)."
      ],
      "metadata": {
        "id": "uLJujZR1NQ7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 1. Create a 2D tensor of shape (6, 4)\n",
        "# Using torch.arange to make the numbers easy to track\n",
        "tensor_6x4 = torch.arange(24).view(6, 4)\n",
        "print(\"Original Tensor (6x4):\\n\", tensor_6x4)\n",
        "\n",
        "# 2. Reshape it into (3, 8)\n",
        "tensor_3x8 = tensor_6x4.view(3, 8)\n",
        "print(\"\\nReshaped Tensor (3, 8):\\n\", tensor_3x8)\n",
        "\n",
        "# 3. Extract specific slices\n",
        "# Slicing syntax: [row_start:row_end, col_start:col_end]\n",
        "# \":\" means select all; \":2\" means select from index 0 up to (but not including) 2\n",
        "sliced_tensor = tensor_3x8[:, :2]\n",
        "print(\"\\nSliced Tensor (All rows, first 2 columns):\\n\", sliced_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWpvVkotOOn4",
        "outputId": "0a8980a2-363d-4254-b7b2-b4de7ebdce99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor (6x4):\n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15],\n",
            "        [16, 17, 18, 19],\n",
            "        [20, 21, 22, 23]])\n",
            "\n",
            "Reshaped Tensor (3, 8):\n",
            " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
            "        [16, 17, 18, 19, 20, 21, 22, 23]])\n",
            "\n",
            "Sliced Tensor (All rows, first 2 columns):\n",
            " tensor([[ 0,  1],\n",
            "        [ 8,  9],\n",
            "        [16, 17]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. NumPy Interoperability\n",
        "PyTorch and NumPy share the same underlying memory when converted on the CPU, making the transition very efficient."
      ],
      "metadata": {
        "id": "j3ly68lRN4DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# NumPy to Torch\n",
        "arr = np.array([1.0, 2.0, 3.0])\n",
        "t = torch.from_numpy(arr)\n",
        "\n",
        "# Operation\n",
        "t = t * 10\n",
        "\n",
        "# Torch to NumPy\n",
        "final_arr = t.numpy()"
      ],
      "metadata": {
        "id": "BZE439S1NTbH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Distributions and StatsThis exercise tests your ability to initialize specific distributions and perform reduction operations.DistributionFunctionParametersUniformtorch.rand(5, 5)Range [0, 1)Normaltorch.randn(5, 5)Mean 0, Std Dev 1Process:Element-wise Multiply: Use the * operator.Stats: result.mean() and result.std().Flatten: result.view(-1) or result.flatten().Sum: result.sum()."
      ],
      "metadata": {
        "id": "_TrqXP27OYyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Uniform Distribution [0, 1)\n",
        "uniform_tensor = torch.rand(5, 5)\n",
        "\n",
        "# 2. Normal Distribution (Mean=0, Std=1)\n",
        "normal_tensor = torch.randn(5, 5)\n",
        "\n",
        "# 3. Element-wise multiplication\n",
        "# Note: This is different from Matrix Multiplication (@)\n",
        "product = uniform_tensor * normal_tensor\n",
        "\n",
        "# 4. Compute Mean and Standard Deviation\n",
        "# Using .item() converts a single-value tensor to a Python number\n",
        "mean_val = product.mean()\n",
        "std_val = product.std()\n",
        "\n",
        "print(f\"Product Mean: {mean_val.item():.4f}\")\n",
        "print(f\"Product Std Dev: {std_val.item():.4f}\")\n",
        "\n",
        "# 5. Reshape into 1D tensor of size 25\n",
        "# -1 tells PyTorch to \"infer\" the dimension based on the remaining elements\n",
        "flattened = product.view(-1)\n",
        "print(f\"\\nFlattened shape: {flattened.shape}\")\n",
        "\n",
        "# 6. Compute sum of all elements\n",
        "total_sum = flattened.sum()\n",
        "print(f\"Sum of all elements: {total_sum.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuxr41fhObWn",
        "outputId": "de70de71-01f0-4a3b-e69c-2d49a03b2a93"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Mean: 0.1173\n",
            "Product Std Dev: 0.4746\n",
            "\n",
            "Flattened shape: torch.Size([25])\n",
            "Sum of all elements: 2.9323\n"
          ]
        }
      ]
    }
  ]
}